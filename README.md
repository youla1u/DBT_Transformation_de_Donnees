# üìä DBT POUR LA TRANSFORMATION DE DONN√âES   

Ce projet illustre un workflow de transformation de donn√©es avec **dbt** en utilisant **DuckDB** comme moteur SQL.   
 
--- 
     
## 1Ô∏è‚É£ Pr√©sentation des donn√©es

J'utilise les donn√©es TLC de 2014 sur les courses de taxis jaunes, verts et VTC, disponibles √† l‚Äôadresse : https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page.

Ces donn√©es, collect√©es par des fournisseurs agr√©√©s, incluent horaires, lieux, distances, tarifs, modes de paiement et passagers d√©clar√©s, avec contr√¥les r√©guliers de la TLC pour en am√©liorer la fiabilit√©.
La description d√©taill√©e de ces colonnes se trouve dans https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf

Les fichiers de donn√©es sont au format .parquet, un format de stockage colonnaire optimis√© pour le traitement de gros volumes de donn√©es. Il permet une compression efficace, une lecture rapide des colonnes n√©cessaires et une meilleure performance pour les analyses sur de grands ensembles de donn√©es.

---

## 2Ô∏è‚É£ Extraction des donn√©es avec SQL dans DuckDB

**Objectif :** importer les donn√©es brutes dans DuckDB pour permettre les premi√®res manipulations et v√©rifications.

**Description :**
Le fichier **sources.yml** dans **models/taxi_trips/** d√©finit l‚Äôemplacement des fichiers Parquet contenant les donn√©es brutes des trajets en taxi jaune pour l‚Äôann√©e 2024.
Il prend en charge deux cas :

>**Donn√©es distantes** : Les fichiers sont directement lus depuis une URL publique

>**Donn√©es locales :** Les fichiers sont stock√©s localement dans le dossier ./output/data/                                                                                 

>Selon le contexte, les fichiers de donn√©es peuvent √™tre lus depuis l‚ÄôURL du site TLC ou depuis un r√©pertoire local (./output/data/). Ici, le r√©pertoire local est choisi, car l‚Äôacc√®s au serveur distant via l‚ÄôURL est limit√© et interroger directement celui-ci peut provoquer des erreurs 403.

Dans les deux cas, les 12 fichiers mensuels sont combin√©s en un seul dataset via la fonction read_parquet et list_transform de DuckDB, expos√© sous le nom **row_yellow_tripdata**.

---

## 3Ô∏è‚É£ Analyse exploratoire de donn√©es via un script SQL

**Objectif :**
R√©aliser des requ√™tes exploratoires sur les donn√©es avant de proc√©der aux transformations:

**Description :**

>**V√©rifier la qualit√© des donn√©es** : 

>d√©tection d‚Äôincoh√©rences (distances n√©gatives, montants nuls ou n√©gatifs).

>Identifier les valeurs manquantes ou atypiques.

>Obtenir un aper√ßu des distributions (r√©partition par vendeur, code tarifaire, type de paiement, zones de d√©part et d‚Äôarriv√©e).

>Mesurer l‚Äôampleur des anomalies afin de d√©cider d‚Äôactions correctives dans les √©tapes de transformation.


>**Analyses initiales r√©alis√©es :**

>Statistiques descriptives

>Comptage du nombre total de trajets par mois.

>Comptage par cat√©gories (VendorID, RatecodeID, payment_type, zones de d√©part/arriv√©e).

>Contr√¥les de coh√©rence

>D√©tection de trajets avec heure de d√©part post√©rieure √† l‚Äôheure d‚Äôarriv√©e.

>D√©tection de trajets avec distance nulle ou n√©gative.

>D√©tection de trajets avec montant total nul ou n√©gatif.

>Aper√ßu des donn√©es

>Extraction des premi√®res lignes pour v√©rifier la structure et les types de colonnes.

---

## 4Ô∏è‚É£ Transformation des donn√©es dans dbt via SQL

**Objectif :** cr√©er des mod√®les SQL **(transform.sql dans models/taxi_trips)** pour nettoyer, enrichir et pr√©parer les donn√©es pour l‚Äôanalyse finale.

**√âtapes principales :**
 1. Chargement des donn√©es brutes depuis la source dbt "row_yellow_tripdata".
 2. Application de filtres pour exclure :
    - trajets sans passager ou avec valeurs incoh√©rentes
    - montants, distances ou dur√©es non valides
    - trajets avec codes de paiement hors carte/cash
    - trajets stock√©s avant transmission (store_and_fwd_flag = 'Y')
 3. Transformations :
    - calcul de la dur√©e de trajet en minutes
    - conversion et typage des colonnes (ex. passenger_count en entier)
    - traduction des codes de paiement en valeurs lisibles ("Credit card", "Cash")
 4. Restriction temporelle aux trajets de l‚Äôann√©e 2024 uniquement.
 5. Production du fichier Parquet final nettoy√© et pr√™t pour les tests unitaires.

---

## 5Ô∏è‚É£ D√©finition et ex√©cution des tests unitaires

**Objectif :** s‚Äôassurer de la qualit√© des donn√©es gr√¢ce aux tests dbt (`unique`, `not_null`, `accepted_values`, etc.).
  
**Tests d√©finis dans schema.yml:**
Ces tests sont d√©claratifs, bas√©s sur des r√®gles standards ou personnalis√©es, appliqu√©s aux colonnes du mod√®le transform.

>**not_null:**
>V√©rifie que la colonne ne contient aucune valeur NULL.
>Exemple : tpep_pickup_datetime, tpep_dropoff_datetime, trip_duration_minutes, etc.

>**accepted_values:**
>V√©rifie que les valeurs d‚Äôune colonne sont dans une liste d√©finie.
>Exemple : payment_method doit √™tre "Credit card" ou "Cash".
>Exemple : store_and_fwd_flag doit √™tre "N".

>**dbt_expectations.expect_column_values_to_be_between:**
>V√©rifie que les valeurs num√©riques sont dans un intervalle donn√©.
>Exemple : passenger_count doit √™tre au moins 1.

>**dbt_expectations.expect_column_values_to_be_of_type:**
>V√©rifie que les valeurs sont du type sp√©cifi√©.
>Exemple : passenger_count est de type BIGINT.


**Tests d√©finis dans des fichiers SQL:**
Ces tests sont bas√©s sur des requ√™tes personnalis√©es ex√©cut√©es sur le mod√®le transform pour v√©rifier des contraintes m√©tier ou d√©tecter des anomalies.

>**Test de couverture des 12 mois:**
>V√©rifie que les donn√©es contiennent bien des trajets pour les 12 mois de l‚Äôann√©e 2024.
>Fichier SQL
>Logique : Extraction des mois distincts, puis √©chec si le nombre de mois ‚â† 12.

>**Test sur passenger_count invalide:**
>Recherche les enregistrements o√π passenger_count est ‚â§ 0 ou non entier.
>Fichier SQL

>**Test sur trip_distance invalide:**
>Recherche les trajets avec une distance ‚â§ 0.
>Fichier SQL

>**Test sur trip_duration_minutes invalide:**
>Recherche les trajets avec une dur√©e ‚â§ 0 minutes.
>Fichier SQL


**R√âSULTAT DU TEST:** 
>Aucune erreur n‚Äôa √©t√© d√©tect√©e. On peut donc sauvegarder les donn√©es transform√©es.
---

## 6Ô∏è‚É£ Sauvegarde des donn√©es transform√©es

Pour sauvegarder les donn√©es transform√©es, on ex√©cute la commande **dbt run**, qui va non seulement enregistrer ces donn√©es dans la table **output/transformed_data.db** de la base de donn√©es, mais aussi dans le fichier **output/trip_2024_transformed.parquet**. Ce fichier contient finalement **34891601** lignes, alors qu'il y avait **41169720** lignes avant la transformation des donn√©es.

---

## üöÄ Commandes principales

**Installation de l‚Äôenvironnement de travail**

1) Creer un repertoire **Projet_DBT/pratique-dbt**

2) Sous Visual Studio ouvrir un terminal, puis se plasser dans **pratique-dbt** 

3) Ex√©cuter les commandes suivantes:
```bash
# Creer un environemennt virtuel.
python -m venv .venv

# Activer l'environemennt virtuel.
.\.venv\Scripts\activate

# Installer DuckDB et dbt 
pip install db-duckdb dbt

# Initialiser un projet dbt 
dbt init formation_dbt

# Pour finir, choisir une base de donn√©es : taper 1 pour s√©lectionner la base de donn√©es propos√©e, ici duckdb.
```
>Pour les prochaines connexions, reactiver l'evironnement depuis le terminal et dans le dossier pratique-dbt.

**Commandes dbt**
```bash
# Nombre de lignes avant les transformations, affich√© directement dans la console.
dbt run-operation count_source_rows

# Pour ex√©cuter toutes les transformations
dbt run

# Pour lancer les tests unitaires √©crits dans schema.yml
dbt test

# Pour lancer les tests unitaires √©crits dans des fichiers SQL, dbt test --select nom_du_fichier_de_test Exemple: 
dbt test --select test_distinct_months 

```

**Commandes DuckDB**
```bash
# 1) Pour explorer directement des donn√©es dans DuckDB
duckdb  
#Puis √©crire une requ√™te SQL d‚Äôexploration de donn√©es.

# 2) Pour explorer des donn√©es dans DuckDB via un fichier_analyse.sql
duckdb
.read './analyses/analyse_exploratiore.sql'
#Cette seconde m√©thode permet de sauvegarder les analyses √† effectuer afin de les reprendre ult√©rieurement ou de les transmettre √† un coll√®gue.

# 3) Pour quitter DuckDB 
.exitpour 

```
